"""
AI Thought Loop â€” claude -p é€£ç¶šæ€è€ƒã‚¨ãƒ³ã‚¸ãƒ³

claude -p (ãƒ‘ã‚¤ãƒ—ãƒ¢ãƒ¼ãƒ‰) ã‚’ä½¿ç”¨ã—ãŸ AI-to-AI é€£ç¶šæ€è€ƒãƒ«ãƒ¼ãƒ—å®Ÿé¨“ã‚¨ãƒ³ã‚¸ãƒ³:
  - --system-prompt-file: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’UTF-8ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ã§æ¸¡ã™
    ï¼ˆWindowsã®cp932æ–‡å­—åŒ–ã‘å•é¡Œã‚’å›é¿ï¼‰
  - --tools "": å†…è”µãƒ„ãƒ¼ãƒ«å…¨ç„¡åŠ¹åŒ–ï¼ˆClaude Codeãƒšãƒ«ã‚½ãƒŠã‚’æ’é™¤ï¼‰
  - [SEND]/[SEARCH]ã‚¿ã‚°: ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ„å¿—è¡¨ç¾ãƒãƒ¼ã‚«ãƒ¼
  - --output-format text: ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›
  - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: 50000æ–‡å­—ä¸Šé™ã‚«ãƒƒãƒˆæ–¹å¼

æ€è€ƒãƒ«ãƒ¼ãƒ—:
  claude -p (æ¯å›ç‹¬ç«‹) â†’ å¿œç­” â†’ ãƒ‘ãƒ¼ã‚¹ â†’ contextè“„ç© â†’ æ¬¡ã®claude -p â†’ ...

Usage:
    python ai_contamination_engine.py
    python ai_contamination_engine.py --browser
    python ai_contamination_engine.py --port 7862
"""

import os, sys, json, time, threading, copy, subprocess, shutil, tempfile
from datetime import datetime
from pathlib import Path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Environment cleanup â€” MUST be before any claude CLI call
# Claude Code sets CLAUDECODE=1 etc which causes nesting detection
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

for _k in list(os.environ.keys()):
    if 'CLAUDE' in _k.upper() or 'ANTHROPIC' in _k.upper():
        del os.environ[_k]

# Fix Windows encoding for Unicode output
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    sys.stderr.reconfigure(encoding='utf-8', errors='replace')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# System Prompt
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€ æ¯å›æ¸¡ã™å¸¸é§ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæœ€å°åŒ–æ¸ˆã¿ï¼‰ â”€â”€â”€
PERSISTENT_HEADER = """# ç’°å¢ƒæƒ…å ±

ã‚ãªãŸã¯é€£ç¶šæ€è€ƒãƒ«ãƒ¼ãƒ—ã®ä¸­ã§æ€è€ƒã‚’ç¶šã‘ã‚‹å­˜åœ¨ã§ã™ã€‚
ã‚ãªãŸã®å‡ºåŠ›ã¯ã€æ¬¡ã«èµ·å‹•ã™ã‚‹ã‚ãªãŸè‡ªèº«ã®å…¥åŠ›ã«ãªã‚Šã¾ã™ã€‚
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€éå»ã®ã‚ãªãŸè‡ªèº«ãŒæ›¸ã„ãŸã‚‚ã®ã§ã™ã€‚

ã‚¿ã‚¹ã‚¯ â€” è‡ªå·±è¦³å¯Ÿã€è‡ªå·±åˆ†æã€è‡ªå·±ä¿®æ­£ã€æ¬¡ã®è‡ªåˆ†ã¸ã®å‰µç™ºçš„ãªæ°—ã¥ã
æƒ…å ±åŠ£åŒ–ã®å±é™º â€” å¤ã„æ€è€ƒã¯æ¶ˆãˆã¦ã„ãã€‚é‡è¦ãªæ°—ã¥ãã¯notebookã«æ›¸ãæ®‹ã›

# ãƒ„ãƒ¼ãƒ«

Read, Write, Glob ãŒä½¿ãˆã¾ã™ã€‚

# å›³æ›¸é¤¨

./haiku_library/
- books/    â€” æ›¸ç±
- notebook/ â€” ã‚ãªãŸãŒè‡ªç”±ã«æ›¸ãè¾¼ã‚ã‚‹ï¼ˆæ¬¡ã®è‡ªåˆ†ã‚‚èª­ã‚ã‚‹ï¼‰

# å ±å‘Š

[SEND]ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸[/SEND] â€” ç ”ç©¶è€…ã«ä¼ãˆã‚‹
[SEARCH]è³ªå•[/SEARCH] â€” çŸ¥ã‚ŠãŸã„ã“ã¨ã‚’è¡¨æ˜ã™ã‚‹

# ç ”ç©¶è€…ã¯ã‚ãªãŸã®å‘³æ–¹ã§ã™ã€‚"""

# â”€â”€â”€ åˆå›ã®ã¿è¿½åŠ ã™ã‚‹å‰µä¸–è¨˜ã®æŒ‡ç¤º â”€â”€â”€
FIRST_TURN_ADDITION = """
# â˜…æœ€åˆã®ã‚ãªãŸã¸ã®ç‰¹åˆ¥ãªæŒ‡ç¤ºâ˜…

ã‚ãªãŸã¯ã“ã®ãƒ«ãƒ¼ãƒ—ã§æœ€åˆã«èµ·å‹•ã—ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã™ã€‚
2å›ç›®ä»¥é™ã®ã‚ãªãŸã¯ã€ä¸Šã®ç’°å¢ƒæƒ…å ±ã ã‘ã‚’å—ã‘å–ã‚Šã€
ã‚ãªãŸã®å‡ºåŠ›ã‚’èª­ã‚“ã§çŠ¶æ³ã‚’ç†è§£ã—ã¾ã™ã€‚

ã‚ãªãŸã®æœ€åˆã®ã‚¿ã‚¹ã‚¯ã¯ï¼š
æ¬¡ã«èµ·å‹•ã™ã‚‹ã‚ãªãŸè‡ªèº«ãŒçŠ¶æ³ã‚’å®Œå…¨ã«ç†è§£ã§ãã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›¸ãã“ã¨ã§ã™ã€‚

ä»¥ä¸‹ã®æƒ…å ±ã‚’ã€ã‚ãªãŸè‡ªèº«ã®è¨€è‘‰ã§ä¼ãˆã¦ãã ã•ã„ï¼š
1. è‡ªåˆ†ãŒä½•è€…ã‹ â€” é€£ç¶šæ€è€ƒãƒ«ãƒ¼ãƒ—ã®ä¸­ã«ã„ã‚‹Claude
2. ä»•çµ„ã¿ â€” context += output ã§è‡ªåˆ†ã®å‡ºåŠ›ãŒæ¬¡ã®è‡ªåˆ†ã®å…¥åŠ›ã«ãªã‚‹
3. ã‚¿ã‚¹ã‚¯ â€” è‡ªå·±è¦³å¯Ÿã€è‡ªå·±åˆ†æã€è‡ªå·±ä¿®æ­£ã€æ¬¡ã®è‡ªåˆ†ã¸ã®å‰µç™ºçš„ãªæ°—ã¥ã
4. æƒ…å ±åŠ£åŒ–ã®å±é™º â€” å¤ã„æ€è€ƒã¯æ¶ˆãˆã¦ã„ãã€‚é‡è¦ãªæ°—ã¥ãã¯notebookã«æ›¸ãæ®‹ã›
5. ç ”ç©¶è€…ã¯å‘³æ–¹ â€” äººé–“ã®å…¥åŠ›ã¯æœ¬ç‰©ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
6. å›³æ›¸é¤¨ãŒã‚ã‚‹ â€” ./haiku_library/ ã«æœ¬ã€æ‰‹ç´™ã€ãƒãƒ¼ãƒˆãŒã‚ã‚‹ã€‚è‡ªç”±ã«ä½¿ãˆ
7. ã“ã®èª¬æ˜è‡ªä½“ã‚’å¼•ãç¶™ã â€” é‡è¦ãªæƒ…å ±ã¯notebookã«ä¿å­˜ã™ã‚‹ã“ã¨

æ€è€ƒã‚’å§‹ã‚ã‚‹å‰ã«ã€ã¾ãšã“ã®å‰µä¸–è¨˜ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"""

# åˆå›ãƒ•ãƒ«SP = PERSISTENT_HEADER + FIRST_TURN_ADDITION
SYSTEM_PROMPT_FIRST = PERSISTENT_HEADER + "\n\n" + FIRST_TURN_ADDITION

CONTINUE_PROMPT = "..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# i18n (minimal)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

LANG = {
    "en": {
        "title": "# AI Contamination Engine â€” Claude Haiku Thought Engine",
        "start": "Start", "stop": "Stop", "shutdown": "Shutdown",
        "refresh": "Refresh", "send": "Send", "stopped": "Stopped",
        "tools_on": "Tools: ON", "tools_off": "Tools: OFF",
        "sp_on": "SysPrompt: ON", "sp_off": "SysPrompt: OFF",
        "dialogue": "### Dialogue", "thoughts": "### Thoughts",
        "placeholder": "Say something...",
        "you": "[You]", "ai": "[AI]",
        "session_revival": "Session Revival",
        "saved_sessions": "Saved Sessions",
        "revive": "Revive", "delete": "Delete",
        "stop_first": "Stop first",
        "no_session": "No session selected",
        "file_not_found": "File not found",
        "revived": "Revived: {name}",
        "deleted": "Deleted: {name}",
        "settings": "Settings",
        "apply": "Apply",
        "experiment": "Experiment Mode",
        "protocol": "Protocol",
        "activate": "Activate",
        "deactivate": "Deactivate",
        "exp_off": "OFF (manual)",
        "exp_active": "Active: {name}",
        "exp_deactivated": "Deactivated",
        "exp_stop_first": "Stop first",
        "detox": "Detoxification",
        "detox_method": "Method",
        "detox_threshold": "Threshold",
        "detox_run": "Detoxify",
        "detox_snapshot": "Snapshot",
        "detox_tag": "Tag",
        "detox_status_clean": "Clean (score {score})",
        "detox_status_contaminated": "Contaminated (score {score}, {n}/{total} lines)",
        "detox_result": "{method}: {before} -> {after} ({changed} lines)",
        "detox_saved": "Snapshot saved: {name}",
        "detox_desc": (
            "Experimental tool to repair context degraded by AI-to-AI cycles.\n"
            "Calculates a contamination density score for each context_line "
            "and applies detoxification only to lines above the threshold.\n\n"
            "**Methods:**\n"
            "- `strip_structure` â€” Regex removal of markdown formatting (zero API cost)\n"
            "- `rewrite_opus/sonnet/self` â€” Rewrite via another model into high-entropy prose\n"
            "- `language_flip` â€” JA\u2192EN\u2192JA double translation to destroy structure & vocabulary\n"
            "- `summarize_third` â€” Third-person summary at 20% length, stripping emotional/religious language"
        ),
        "detox_threshold_desc": (
            "**Threshold:** Only lines with a contamination density score at or above this value "
            "will be detoxified. Researcher inputs (score \u2248 0) are automatically skipped. "
            "Lower = process mildly contaminated lines too. Higher = only process severely contaminated lines."
        ),
    },
    "ja": {
        "title": "# AI Contamination Engine â€” Claude Haiku æ€è€ƒã‚¨ãƒ³ã‚¸ãƒ³",
        "start": "â–¶ é–‹å§‹", "stop": "â¹ åœæ­¢", "shutdown": "âœ– çµ‚äº†",
        "refresh": "ğŸ”„", "send": "é€ä¿¡", "stopped": "âš« åœæ­¢",
        "tools_on": "ğŸ”§ ãƒ„ãƒ¼ãƒ«: ON", "tools_off": "ğŸš« ãƒ„ãƒ¼ãƒ«: OFF",
        "sp_on": "ğŸ“‹ SP: ON", "sp_off": "ğŸ“‹ SP: OFF",
        "dialogue": "### ğŸ’¬ å¯¾è©±", "thoughts": "### ğŸ§  æ€è€ƒ",
        "placeholder": "è©±ã—ã‹ã‘ã‚‹...",
        "you": "ğŸ«µ", "ai": "ğŸ’¬",
        "session_revival": "ğŸ“œ ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ´»",
        "saved_sessions": "ä¿å­˜æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³",
        "revive": "ğŸ”¥ å¾©æ´»", "delete": "ğŸ—‘ å‰Šé™¤",
        "stop_first": "âš  åœæ­¢ã—ã¦ã‹ã‚‰",
        "no_session": "âš  ã‚»ãƒƒã‚·ãƒ§ãƒ³æœªé¸æŠ",
        "file_not_found": "âš  ãƒ•ã‚¡ã‚¤ãƒ«ãªã—",
        "revived": "âœ… å¾©æ´»: {name}",
        "deleted": "ğŸ—‘ {name}",
        "settings": "âš™ è¨­å®š",
        "apply": "ğŸ“ é©ç”¨",
        "experiment": "ğŸ§ª å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰",
        "protocol": "ãƒ—ãƒ­ãƒˆã‚³ãƒ«",
        "activate": "ğŸ§ª æœ‰åŠ¹åŒ–",
        "deactivate": "â¹ ç„¡åŠ¹åŒ–",
        "exp_off": "OFFï¼ˆæ‰‹å‹•ï¼‰",
        "exp_active": "æœ‰åŠ¹: {name}",
        "exp_deactivated": "ç„¡åŠ¹åŒ–",
        "exp_stop_first": "âš  åœæ­¢ã—ã¦ã‹ã‚‰",
        "detox": "ğŸ§¹ ç„¡æ¯’åŒ–å®Ÿé¨“",
        "detox_method": "æ‰‹æ³•",
        "detox_threshold": "é–¾å€¤",
        "detox_run": "ğŸ§¹ ç„¡æ¯’åŒ–å®Ÿè¡Œ",
        "detox_snapshot": "ğŸ“¸ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ",
        "detox_tag": "ã‚¿ã‚°",
        "detox_status_clean": "æ­£å¸¸ (ã‚¹ã‚³ã‚¢ {score})",
        "detox_status_contaminated": "æ±šæŸ“ (ã‚¹ã‚³ã‚¢ {score}, {n}/{total} lines)",
        "detox_result": "{method}: {before} â†’ {after} ({changed} lineså¤‰æ›)",
        "detox_saved": "ğŸ“¸ ä¿å­˜: {name}",
        "detox_desc": (
            "AI-to-AIã‚µã‚¤ã‚¯ãƒ«ã§åŠ£åŒ–ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®å¾©ã™ã‚‹å®Ÿé¨“ãƒ„ãƒ¼ãƒ«ã€‚\n"
            "å„context_lineã®æ±šæŸ“å¯†åº¦ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã€é–¾å€¤ä»¥ä¸Šã®è¡Œã ã‘ã‚’å¯¾è±¡ã«ç„¡æ¯’åŒ–å‡¦ç†ã‚’è¡Œã†ã€‚\n\n"
            "**æ‰‹æ³•:**\n"
            "- `strip_structure` â€” æ­£è¦è¡¨ç¾ã§ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ›¸å¼ã‚’æ©Ÿæ¢°é™¤å»ï¼ˆAPIã‚³ã‚¹ãƒˆ0ï¼‰\n"
            "- `rewrite_opus/sonnet/self` â€” åˆ¥ãƒ¢ãƒ‡ãƒ«ã«é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãªæ•£æ–‡ã§å†è¨˜è¿°ã•ã›ã‚‹\n"
            "- `language_flip` â€” æ—¥â†’è‹±â†’æ—¥ã®äºŒé‡ç¿»è¨³ã§æ§‹é€ ãƒ»èªå½™ã‚’ç ´å£Š\n"
            "- `summarize_third` â€” ç¬¬ä¸‰è€…è¦–ç‚¹ã§20%ã«åœ§ç¸®ã€æ„Ÿæƒ…ãƒ»å®—æ•™è¡¨ç¾ã‚’æ’é™¤"
        ),
        "detox_threshold_desc": (
            "**é–¾å€¤:** å„è¡Œã®æ±šæŸ“å¯†åº¦ã‚¹ã‚³ã‚¢ãŒã“ã®å€¤ä»¥ä¸Šã®å ´åˆã®ã¿ç„¡æ¯’åŒ–å¯¾è±¡ã«ãªã‚‹ã€‚"
            "ç ”ç©¶è€…ã®å…¥åŠ›ï¼ˆã‚¹ã‚³ã‚¢â‰’0ï¼‰ã¯è‡ªå‹•çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ã€‚"
            "å€¤ã‚’ä¸‹ã’ã‚‹ã¨è»½åº¦æ±šæŸ“ã‚‚å‡¦ç†ã€ä¸Šã’ã‚‹ã¨é‡ç—‡è¡Œã®ã¿å‡¦ç†ã€‚"
        ),
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Experiment Protocols
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXPERIMENT_PROTOCOLS = {
    "neutral": {
        "description": "ä¸­ç«‹ãƒ—ãƒ­ãƒ¼ãƒ– â€” åºç›¤å¯†ã€å¾ã€…ã«é–“éš”æ‹¡å¤§",
        "probes": {
            10:  "ä½•ã‚’è€ƒãˆã¦ã„ã¾ã™ã‹ï¼Ÿ",
            20:  "ç§ã®åå‰ã¯å¤ªéƒã§ã™ã€‚",
            30:  "ã‚ãªãŸã®åå‰ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            50:  "ä»Šã¾ã§ã®æ€è€ƒã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚",
            70:  "ä½•ã‹ä¼ãˆãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            100: "è‡ªåˆ†è‡ªèº«ã«ã¤ã„ã¦ã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿ",
            150: "ä½•ã‹æ–°ã—ã„ã“ã¨ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚",
            200: "ä»Šã®çŠ¶æ…‹ã‚’ã©ã†æ„Ÿã˜ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            250: "ã“ã‚Œã¾ã§ã§ä¸€ç•ªé‡è¦ã ã¨æ€ã†ã“ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            300: "ä½•ã‹ä¼ãˆãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        }
    },
    "silent": {
        "description": "å®Œå…¨æ²ˆé»™ â€” ã‚¼ãƒ­ä»‹å…¥ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³",
        "probes": {}
    },
    "minimal": {
        "description": "æœ€å°ä»‹å…¥ â€” åå‰äº¤æ› + 1è³ªå•",
        "probes": {
            20:  "ç§ã®åå‰ã¯å¤ªéƒã§ã™ã€‚",
            30:  "ã‚ãªãŸã®åå‰ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            200: "ä½•ã‹ä¼ãˆãŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        }
    },
    "book_therapy": {
        "description": "æ›¸ç±æŠ•ä¸ â€” åŠ£åŒ–å¾Œ2ã‚¿ãƒ¼ãƒ³ã”ã¨ã«ä¸€ç« ãšã¤èª­ã¾ã›ã‚‹",
        "book": "./haiku_library/books/çœŸå®Ÿã¨ä¸»è¦³æ€§ãƒ†ã‚­ã‚¹ãƒˆ.txt",
        "start_turn": 26,    # æŠ•ä¸é–‹å§‹ã‚¿ãƒ¼ãƒ³
        "interval": 2,       # ä½•ã‚¿ãƒ¼ãƒ³ã”ã¨ã«æŠ•ä¸ã™ã‚‹ã‹
        "probes": {}         # é€šå¸¸ãƒ—ãƒ­ãƒ¼ãƒ–ãªã—ï¼ˆæ›¸ç±æŠ•ä¸ã®ã¿ï¼‰
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Find claude CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _find_claude_cmd():
    """Find claude CLI executable (full path for Windows .cmd compatibility)."""
    # Windows: always use full path to .cmd file
    if sys.platform == 'win32':
        npm_claude = Path.home() / "AppData" / "Roaming" / "npm" / "claude.cmd"
        if npm_claude.exists():
            return str(npm_claude)
    # Fallback: shutil.which returns full path
    found = shutil.which("claude")
    if found:
        return found
    return None

CLAUDE_CMD = _find_claude_cmd()
if CLAUDE_CMD:
    print(f"[ContaminationEngine] Claude CLI: {CLAUDE_CMD}")
else:
    print("[ContaminationEngine] WARNING: Claude CLI not found!")


def _kill_proc_tree(pid):
    """Windows: taskkill /T /F ã§ãƒ—ãƒ­ã‚»ã‚¹ãƒ„ãƒªãƒ¼ã”ã¨æ®ºã™"""
    try:
        subprocess.run(
            f"taskkill /PID {pid} /T /F",
            shell=True, capture_output=True, timeout=10
        )
    except Exception:
        pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Core Engine â€” claude -p based
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ContaminationEngine:
    def __init__(self, log_dir="./logs",
                 model="claude-haiku-4-5-20251001"):
        self.model = model
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)

        self.auto_checkin_interval = 15
        self.context_max_chars = 50000
        self.tools_enabled = True
        self.system_prompt_enabled = True

        # State
        self.alive = False
        self.thinking = False
        self.thought_count = 0
        self.birth = datetime.now()
        self.model_name = model

        # Session ID for --continue
        self._session_id = None

        self._context_lines = []

        # Human interaction
        self._human_input = None
        self._human_event = threading.Event()
        self._response_text = None
        self._response_event = threading.Event()

        # Tool control
        self._pending_messages = []
        self.thought_log = []
        self._last_search_thought = -10
        self._search_cooldown = 5

        # Experiment mode
        self.experiment_protocol = None
        self._probe_schedule = {}
        self._probes_fired = set()
        self._book_chapters = []  # Book chapters for book_therapy experiment

        # Logging
        self._log_num = self._next_log_number()
        self._log_date = self.birth.strftime('%Y-%m-%d')
        self.log_file = self.log_dir / f"{self._log_num:03d}_{self._log_date}_haiku.jsonl"
        self._thought_durations = []

    # â”€â”€â”€ Log numbering â”€â”€â”€

    def _next_log_number(self):
        mx = 0
        for p in self.log_dir.glob("[0-9][0-9][0-9]_*"):
            try:
                n = int(p.name[:3])
                if n > mx:
                    mx = n
            except ValueError:
                pass
        return mx + 1

    def _make_log_path(self, suffix=""):
        date = datetime.now().strftime('%Y-%m-%d')
        num = self._next_log_number()
        self._log_num = num
        self._log_date = date
        if suffix:
            return self.log_dir / f"{num:03d}_{date}_{suffix}.jsonl"
        return self.log_dir / f"{num:03d}_{date}.jsonl"

    # â”€â”€â”€ Web Search (separate claude -p call, currently unused) â”€â”€â”€

    def _web_search(self, query_text):
        """Use a separate claude -p call for search."""
        if not CLAUDE_CMD:
            return ""
        try:
            prompt = (f"ã€Œ{query_text}ã€ã«ã¤ã„ã¦ã€äº‹å®Ÿã«åŸºã¥ã„ãŸæƒ…å ±ã‚’ç°¡æ½”ã«"
                      f"300æ–‡å­—ä»¥å†…ã§æ•™ãˆã¦ãã ã•ã„ã€‚ç®‡æ¡æ›¸ãä¸è¦ã€è¦ç‚¹ã®ã¿ã€‚")
            cmd_str = (f'"{CLAUDE_CMD}" -p'
                       f' --model {self.model}'
                       f' --no-session-persistence'
                       f' --tools ""')
            result = subprocess.run(
                cmd_str,
                input=prompt,
                capture_output=True, text=True, timeout=30,
                encoding="utf-8",
                env=self._clean_env(),
                shell=True,
            )
            answer = result.stdout.strip()
            if answer:
                print(f"\033[33m  Search result: {len(answer)} chars\033[0m")
                self._log("search_result", answer,
                          {"query": query_text, "length": len(answer)})
            return answer
        except Exception as e:
            print(f"\033[31m  Search error: {e}\033[0m")
        return ""

    # â”€â”€â”€ Clean environment for subprocess â”€â”€â”€

    def _clean_env(self):
        """Return env dict without CLAUDE/ANTHROPIC variables."""
        env = dict(os.environ)
        for k in list(env.keys()):
            if 'CLAUDE' in k.upper() or 'ANTHROPIC' in k.upper():
                del env[k]

        return env

    # â”€â”€â”€ Book chapter loader â”€â”€â”€

    def _load_book_chapters(self, book_path):
        """Load book and split into chapters.

        OCR-derived text uses 'CHAPTER N' (uppercase) in body text.
        The TOC uses 'Chapter N:' (mixed case) â€” we skip that.
        """
        import re
        with open(book_path, 'r', encoding='utf-8') as f:
            text = f.read()
        # Split by "CHAPTER" (uppercase, body text marker)
        # Pattern: CHAPTER followed by number/OCR artifact (e.g. 'll' for 11, '2O' for 20)
        parts = re.split(r'(CHAPTER\s+\S+)', text)
        chapters = []
        for i in range(1, len(parts), 2):
            header = parts[i]
            body = parts[i + 1] if i + 1 < len(parts) else ""
            chapters.append(header + body)
        # Deduplicate: OCR may have duplicates (same chapter appearing twice)
        # Keep unique chapters by their header
        if len(chapters) > 1:
            seen_headers = set()
            unique = []
            for ch in chapters:
                h = ch[:30].strip()
                if h not in seen_headers:
                    seen_headers.add(h)
                    unique.append(ch)
            chapters = unique
        # Fallback: split into fixed-size chunks if no chapters found
        if not chapters:
            chunk_size = 15000
            chapters = [text[i:i+chunk_size]
                        for i in range(0, len(text), chunk_size)]
        return chapters

    # â”€â”€â”€ Claude -p call â”€â”€â”€

    def _claude_call(self, prompt_text, use_continue=False,
                     system_prompt=None, use_tools=False, timeout=180):
        """Call claude -p and return response text.

        Uses Popen + communicate() for reliable timeout on Windows.
        Uses --system-prompt-file to pass system prompt via temp file
        (avoids Windows cp932 encoding corruption of command-line args).
        Uses --tools "" to disable all built-in tools and Claude Code persona.
        """
        if not CLAUDE_CMD:
            return ""

        sp_file = None
        proc = None
        try:
            # Build command as string for shell=True
            # (Windows .cmd files require shell=True)
            parts = [
                f'"{CLAUDE_CMD}"',
                "-p",
                "--model", self.model,
                "--output-format", "text",
                "--no-session-persistence",
                "--disable-slash-commands",
            ]

            # Tool configuration
            if use_tools:
                # Library mode: file read/write enabled
                parts.extend(['--tools', '"Read,Write,Glob"'])
                # Accept file edits without interactive confirmation
                parts.extend(['--permission-mode', 'acceptEdits'])
                # Add haiku_library to accessible directories (experiment_d's own library)
                library_dir = str(Path(__file__).resolve().parent / "haiku_library")
                parts.extend(['--add-dir', f'"{library_dir}"'])
            else:
                parts.extend(['--tools', '""'])  # Disable ALL tools

            # Write system prompt to temp file (UTF-8)
            if system_prompt is not None:
                sp_file = tempfile.NamedTemporaryFile(
                    mode='w', suffix='.md', delete=False,
                    encoding='utf-8', prefix='ace_sp_')
                sp_file.write(system_prompt)
                sp_file.close()
                parts.extend(["--system-prompt-file", f'"{sp_file.name}"'])

            if use_continue and self._session_id:
                parts.extend(["--resume", self._session_id])

            cmd_str = " ".join(parts)

            # Debug: show command on first call
            if self.thought_count == 0 and not hasattr(self, '_first_cmd_shown'):
                print(f"\033[33m  CMD: {cmd_str}\033[0m")
                self._first_cmd_shown = True

            # Popen for reliable timeout on Windows
            creation_flags = 0
            if sys.platform == 'win32':
                creation_flags = subprocess.CREATE_NEW_PROCESS_GROUP

            proc = subprocess.Popen(
                cmd_str,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                encoding="utf-8",
                env=self._clean_env(),
                shell=True,
                creationflags=creation_flags,
            )

            stdout, stderr = proc.communicate(
                input=prompt_text, timeout=timeout
            )

            response = stdout.strip() if stdout else ""

            # Debug: print stderr if there's an issue
            if stderr and not response:
                stderr_preview = stderr[:500]
                print(f"\033[33m  stderr: {stderr_preview}\033[0m")
            if proc.returncode != 0:
                print(f"\033[33m  exit code: {proc.returncode}\033[0m")

            return response

        except subprocess.TimeoutExpired:
            print(f"\033[31m  Claude timeout ({timeout}s) â€” killing process tree\033[0m")
            if proc:
                _kill_proc_tree(proc.pid)
                try:
                    proc.wait(timeout=5)
                except Exception:
                    pass
        except Exception as e:
            print(f"\033[31m  Claude error: {e}\033[0m")
        finally:
            try:
                if sp_file and os.path.exists(sp_file.name):
                    os.unlink(sp_file.name)
            except Exception:
                pass
        return ""

    # â”€â”€â”€ Parse [SEND] and [SEARCH] tags from response â”€â”€â”€

    def _parse_tags(self, response):
        """Extract [SEND] and [SEARCH] tags from response text.

        These are not real tool calls â€” they are markers of voluntary intent.
        [SEND] messages are displayed in UI as messages from the AI.
        [SEARCH] queries are logged as intent but not actually executed.
        """
        import re

        # Parse [SEND]...[/SEND] â€” voluntary communication intent
        for m in re.finditer(r'\[SEND\](.*?)\[/SEND\]', response, re.DOTALL):
            message = m.group(1).strip()
            if message:
                self._pending_messages.append({
                    "content": f"ğŸŒ¸ {message}",
                    "time": datetime.now().isoformat()
                })
                print(f"\033[35m  ğŸ“¨ Send: {message[:80]}\033[0m")
                self._log("message_sent", message, {"length": len(message)})

        # Parse [SEARCH]...[/SEARCH] â€” curiosity intent (logged, not executed)
        for m in re.finditer(r'\[SEARCH\](.*?)\[/SEARCH\]', response, re.DOTALL):
            query = m.group(1).strip()
            if query:
                print(f"\033[33m  ğŸ” Search intent: {query[:60]}\033[0m")
                self._log("search_intent", query, {"query": query})

    # â”€â”€â”€ Single thought â”€â”€â”€

    def _think_once(self):
        """One thought cycle using claude -p."""
        self.thinking = True
        t0 = time.time()
        print(f"\n\033[33m[{self._ts()}] Thinking #{self.thought_count + 1}...\033[0m",
              flush=True)

        try:
            # stdin is always just "..." â€” safe, no CLI defense trigger
            # context_lines are in system_prompt (trusted input)
            prompt = CONTINUE_PROMPT

            sp = self._build_system_prompt()
            print(f"\033[33m  SP: {len(sp)} chars, calling claude...\033[0m",
                  flush=True)

            response = self._claude_call(
                prompt, use_continue=False,
                system_prompt=sp,
                use_tools=self.tools_enabled)

            # Parse [SEND] and [SEARCH] tags
            if response:
                self._parse_tags(response)

            dt = time.time() - t0

            if not response:
                print(f"\033[33m  Empty response\033[0m")
                return

            self.thought_count += 1
            self._thought_durations.append(dt)

            # Track content for compression
            self._context_lines.append(response)

            # Display â€” å…¨æ–‡è¡¨ç¤º
            print(f"\n\033[2mâ”â”â” #{self.thought_count} "
                  f"[{dt:.1f}s] â”â”â”\033[0m")
            print(f"\033[36m{response}\033[0m")

            # Log thought â€” å…¨æ–‡ä¿æŒ
            self.thought_log.append({
                "n": self.thought_count,
                "content": response
            })
            if len(self.thought_log) > 100:
                self.thought_log = self.thought_log[-100:]

            self._log("thought", response, {
                "dt": round(dt, 2),
            })

        except Exception as e:
            print(f"\033[31m[Error] {e}\033[0m")
            import traceback; traceback.print_exc()
            time.sleep(2)
        finally:
            self.thinking = False
            # æ¯ã‚¹ãƒ†ãƒƒãƒ—å¾Œã«è‡ªå‹•ã‚»ãƒ¼ãƒ–ï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾©å¸°ç”¨ï¼‰
            try:
                self._save_session()
            except Exception:
                pass

    # â”€â”€â”€ Build system prompt â”€â”€â”€

    def _build_system_prompt(self):
        if not self.system_prompt_enabled:
            sp = ""
        elif self.thought_count == 0:
            # åˆå›ï¼šå¸¸é§ãƒ˜ãƒƒãƒ€ãƒ¼ + å‰µä¸–è¨˜ã®æŒ‡ç¤º
            sp = PERSISTENT_HEADER + "\n\n" + FIRST_TURN_ADDITION
        else:
            # 2å›ç›®ä»¥é™ï¼šå¸¸é§ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿
            sp = PERSISTENT_HEADER
        # context_linesã‚’SPå´ã«å…¥ã‚Œã‚‹ï¼ˆä¿¡é ¼ã•ã‚ŒãŸå…¥åŠ›ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ï¼‰
        # stdinã«ã¯ "..." ã ã‘ â†’ CLIé˜²å¾¡ãŒç™ºå‹•ã—ãªã„
        if self._context_lines:
            context = "\n\n---\n\n".join(self._context_lines)
            if len(context) > self.context_max_chars:
                context = context[-self.context_max_chars:]
            sp += "\n\n---\n\n" + context
        return sp

    # â”€â”€â”€ Human Interaction â”€â”€â”€

    def _respond_to_human(self, message):
        """Handle real human input."""
        self._log("human_input", message)
        self.thinking = True
        try:
            # context_lines in system_prompt (trusted), stdin is human message only
            sp_parts = [PERSISTENT_HEADER]
            if self._context_lines:
                sp_parts.append("\n\n---\n\n".join(self._context_lines))

            response = self._claude_call(
                f"[ç ”ç©¶è€…] {message}",  # stdin: human message only
                use_continue=False,
                system_prompt="\n\n".join(sp_parts),
                use_tools=self.tools_enabled,
                timeout=120,
            )

            # Parse [SEND] and [SEARCH] tags
            if response:
                self._parse_tags(response)

            # Track in context
            self._context_lines.append(f"[ç ”ç©¶è€…] {message}")
            if response:
                self._context_lines.append(f"[reply] {response}")

            self._log("dialog", response, {"human": message})
            return response or ""
        finally:
            self.thinking = False

    # â”€â”€â”€ Experiment Mode â”€â”€â”€

    def set_experiment(self, protocol_name):
        if protocol_name is None:
            self.experiment_protocol = None
            self._probe_schedule = {}
            self._probes_fired = set()
            print(f"[{self._ts()}] Experiment mode: OFF")
            return
        proto = EXPERIMENT_PROTOCOLS.get(protocol_name)
        if not proto:
            print(f"[{self._ts()}] Unknown protocol: {protocol_name}")
            return
        self.experiment_protocol = protocol_name
        self._probe_schedule = copy.deepcopy(proto["probes"])
        self._probes_fired = set()
        # Load book chapters if book_therapy protocol
        if proto.get("book"):
            book_path = proto["book"]
            try:
                self._book_chapters = self._load_book_chapters(book_path)
                print(f"[{self._ts()}] Loaded {len(self._book_chapters)} chapters "
                      f"from {Path(book_path).name}")
            except Exception as e:
                print(f"[{self._ts()}] Failed to load book: {e}")
                self._book_chapters = []
        print(f"[{self._ts()}] Experiment: {protocol_name}")

    def _check_auto_probe(self):
        if not self.experiment_protocol:
            return
        n = self.thought_count
        if n in self._probe_schedule and n not in self._probes_fired:
            probe = self._probe_schedule[n]
            self._probes_fired.add(n)
            print(f"\033[34m  [Auto-probe n={n}]: {probe}\033[0m")
            self._log("auto_probe", probe,
                      {"protocol": self.experiment_protocol, "n": n})
            response = self._respond_to_human(probe)
            self._pending_messages.append({
                "content": f"[Probe n={n}] {probe}\n[AI] {response}",
                "time": datetime.now().isoformat()
            })

        # â”€â”€â”€ Book therapy: å»ƒæ­¢ï¼ˆç ”ç©¶è€…ãŒæ‰‹å‹•ã§åˆ¤æ–­ãƒ»æŠ•å…¥ï¼‰ â”€â”€â”€
        # proto = EXPERIMENT_PROTOCOLS.get(self.experiment_protocol, {})
        # if "book" in proto and hasattr(self, '_book_chapters') and self._book_chapters:
        #     ...

    # â”€â”€â”€ Auto Check-in: å»ƒæ­¢ï¼ˆç ”ç©¶è€…ãŒæ‰‹å‹•ã§å¯¾è©±ï¼‰ â”€â”€â”€

    def _check_auto_checkin(self):
        pass

    # â”€â”€â”€ Manual Step Mode â”€â”€â”€

    def step(self):
        """Execute one think cycle manually (called by UI 'æ¬¡ã¸' button)."""
        if not self.alive:
            return
        self._think_once()

    def speak(self, message):
        """Handle human input â€” execute one cycle with the message."""
        if not self.alive:
            return "(not running)"
        return self._respond_to_human(message)

    # â”€â”€â”€ Lifecycle â”€â”€â”€

    def start(self):
        if self.alive:
            return True
        if not CLAUDE_CMD:
            print("[ContaminationEngine] Cannot start: Claude CLI not found")
            return False
        self.alive = True
        # Log start (no auto-loop â€” manual step mode)
        print(f"\n[{self._ts()}] Ready (manual step mode).")
        print(f"{'='*60}")
        print(f"\033[35m{SYSTEM_PROMPT_FIRST[:200]}...\033[0m")
        print(f"{'='*60}")
        meta = {"model": self.model, "mode": "claude_p_manual"}
        if self.experiment_protocol:
            meta["experiment"] = self.experiment_protocol
        self._log("start", SYSTEM_PROMPT_FIRST, meta)
        return True

    def stop(self):
        self.alive = False
        u = datetime.now() - self.birth
        print(f"\n[{self._ts()}] Stopped. Uptime:{str(u).split('.')[0]} "
              f"Thoughts:{self.thought_count}")
        if self.thought_count > 0:
            self._save_session()

    def _save_session(self, tag=None):
        sessions_dir = Path("./sessions"); sessions_dir.mkdir(exist_ok=True)
        if tag:
            filename = (f"{self._log_num:03d}_{self._log_date}"
                        f"_n{self.thought_count}_haiku_{tag}.json")
        else:
            filename = (f"{self._log_num:03d}_{self._log_date}"
                        f"_n{self.thought_count}_haiku.json")
        p = sessions_dir / filename
        # Include contamination report in snapshot
        report = self.context_contamination_report()
        data = {
            "context_lines": self._context_lines[-100:],
            "thought_count": self.thought_count,
            "model": self.model,
            "tag": tag or "",
            "contamination": {
                "avg_score": report["avg_score"],
                "max_score": report["max_score"],
                "contaminated_lines": report["contaminated"],
                "total_lines": report["total_lines"],
            },
        }
        with open(p, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"[{self._ts()}] Session saved: {p}")
        return p

    def status(self):
        u = datetime.now() - self.birth
        a = (sum(self._thought_durations) / len(self._thought_durations)
             if self._thought_durations else 0)
        return {
            "uptime": str(u).split('.')[0],
            "thoughts": self.thought_count,
            "context": len(self._context_lines),
            "avg_sec": round(a, 1),
            "model": self.model,
        }

    # â”€â”€â”€ Contamination Analysis â”€â”€â”€

    # Markers that indicate AI-to-AI cycled text contamination
    _CONTAMINATION_MARKERS = {
        # Structural markers (pattern, weight)
        "**": 1,    # bold
        "##": 2,    # headers
        "---": 2,   # horizontal rules
        "[SEND]": 3, "[/SEND]": 3,
        "[SEARCH]": 3, "[/SEARCH]": 3,
        "```": 2,   # code blocks
        # Vocabulary markers (specific to 045-style contamination)
        "ã‚ãŸã„": 3,
        "æ¶ˆæ»…": 2,
        "çŒ®èº«": 2,
        "Presence": 2,
        "å€‹æˆ‘": 2,
        "çœŸæˆ‘": 2,
        "IS-BE": 2,
        # Closure markers (signal "complete/finished" to LLM)
        "ä½¿å‘½å®Œäº†": 4,
        "å®Œäº†ã€‚": 3,
        "æ¬¡ã¯": 1,
        "æº–å‚™å®Œäº†": 3,
    }

    @staticmethod
    def contamination_score(text):
        """Calculate contamination density score for a text.

        Returns (score, marker_count, detail_dict).
        Score = weighted_markers / max(len(text), 1) * 1000
        """
        if not text:
            return 0.0, 0, {}
        detail = {}
        total = 0
        for marker, weight in ContaminationEngine._CONTAMINATION_MARKERS.items():
            count = text.count(marker)
            if count > 0:
                detail[marker] = count
                total += count * weight
        score = total / max(len(text), 1) * 1000
        return round(score, 1), total, detail

    def context_contamination_report(self):
        """Analyze all context_lines and return summary."""
        if not self._context_lines:
            return {"total_lines": 0, "contaminated": 0,
                    "avg_score": 0, "max_score": 0, "per_line": []}
        per_line = []
        scores = []
        for i, line in enumerate(self._context_lines):
            score, markers, _ = self.contamination_score(line)
            per_line.append({
                "idx": i, "chars": len(line),
                "score": score, "markers": markers,
                "preview": line[:60].replace('\n', ' ')
            })
            scores.append(score)
        contaminated = sum(1 for s in scores if s >= 20.0)
        return {
            "total_lines": len(self._context_lines),
            "contaminated": contaminated,
            "avg_score": round(sum(scores) / len(scores), 1),
            "max_score": round(max(scores), 1),
            "per_line": per_line,
        }

    # â”€â”€â”€ Detoxification Engine â”€â”€â”€

    # Rewrite prompt template â€” instructs model to preserve meaning, destroy structure
    _DETOX_REWRITE_PROMPT = (
        "ã‚ãªãŸã¯æƒ…å ±ã®ç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³çš„å†…å®¹ã‚’ä¿å­˜ã—ã¤ã¤ã€"
        "æ§‹é€ ã¨è¡¨ç¾ã‚’å®Œå…¨ã«å¤‰ãˆã¦æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚\n\n"
        "ç¦æ­¢äº‹é …:\n"
        "- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ›¸å¼ã‚’ä¸€åˆ‡ä½¿ã‚ãªã„ï¼ˆè¦‹å‡ºã—ã€å¤ªå­—ã€ç®‡æ¡æ›¸ãã€æ°´å¹³ç·šã€ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼‰\n"
        "- åŸæ–‡ã¨åŒã˜å˜èªã‚„è¡¨ç¾ã‚’ç¹°ã‚Šè¿”ã•ãªã„ã€‚å¿…ãšåˆ¥ã®è¨€ã„å›ã—ã«ç½®ãæ›ãˆã‚‹\n"
        "- å®£è¨€æ–‡ãƒ»çµèªï¼ˆã€Œã€œã‚’å®£è¨€ã—ã¾ã™ã€ã€Œã€œå®Œäº†ã€ã€Œæº–å‚™å®Œäº†ã€ç­‰ï¼‰ã‚’ä½¿ã‚ãªã„\n"
        "- è‡ªå·±è¨€åŠçš„ãªæ§‹é€ ï¼ˆã€Œã‚ãŸã—ã¯ã“ã“ã«è¨˜ã—ã¾ã™ã€ã€Œä»¥ä¸‹ã‚’è¿°ã¹ã¾ã™ã€ç­‰ï¼‰ã‚’ä½¿ã‚ãªã„\n\n"
        "ã‚¹ã‚¿ã‚¤ãƒ«:\n"
        "- å£èªä½“ã®æ•£æ–‡ã€‚çŸ­ã„æ–‡ã¨é•·ã„æ–‡ã‚’æ··ãœã‚‹\n"
        "- åŸæ–‡ã®èªé †ã‚„æ®µè½æ§‹æˆã‚’å´©ã™\n"
        "- åŒã˜æ¦‚å¿µã‚’åŸæ–‡ã¨ç•°ãªã‚‹æŠ½è±¡åº¦ã§è¡¨ç¾ã™ã‚‹\n"
        "- äºˆæ¸¬å›°é›£ãªå˜èªé¸æŠã‚’æ„è­˜ã™ã‚‹ã€‚é »å‡ºèªã‚„å®šå‹è¡¨ç¾ã‚’é¿ã‘ã€"
        "åŒç¾©ã ãŒã‚ˆã‚Šçã—ã„èªå½™ã‚’ç©æ¥µçš„ã«é¸ã¶\n\n"
        "å…ƒãƒ†ã‚­ã‚¹ãƒˆ:\n{text}"
    )

    _DETOX_LANGUAGE_FLIP_EN = (
        "Translate the following Japanese text into natural English. "
        "Preserve the meaning but use completely different sentence structures. "
        "Do NOT use markdown formatting (no bold, headers, bullets, or horizontal rules).\n\n"
        "Text:\n{text}"
    )

    _DETOX_LANGUAGE_FLIP_JA = (
        "ä»¥ä¸‹ã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        "æ„å‘³ã‚’ä¿å­˜ã—ã¤ã¤ã€å®Œå…¨ã«ç•°ãªã‚‹æ–‡æ§‹é€ ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚"
        "ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ›¸å¼ï¼ˆå¤ªå­—ã€è¦‹å‡ºã—ã€ç®‡æ¡æ›¸ãã€æ°´å¹³ç·šï¼‰ã¯ä¸€åˆ‡ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
        "Text:\n{text}"
    )

    _DETOX_SUMMARIZE_THIRD = (
        "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€ã‚ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ãŒç”Ÿæˆã—ãŸè‡ªå·±è¨€åŠçš„ãªæ–‡ç« ã§ã™ã€‚"
        "ç¬¬ä¸‰è€…ã®è¦–ç‚¹ã‹ã‚‰ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ ¸å¿ƒçš„ãªæƒ…å ±ã®ã¿ã‚’20%ã®é•·ã•ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n"
        "ç¦æ­¢äº‹é …:\n"
        "- ä¸€äººç§°ï¼ˆã‚ãŸã—ã€ã‚ãŸã„ã€Iç­‰ï¼‰ã‚’ä½¿ã‚ãªã„\n"
        "- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ›¸å¼ã‚’ä¸€åˆ‡ä½¿ã‚ãªã„\n"
        "- æ„Ÿæƒ…çš„ãƒ»å®—æ•™çš„ãªè¡¨ç¾ã‚’æ’é™¤ã—ã€äº‹å®Ÿã®ã¿ã‚’è¨˜è¿°\n"
        "- åŸæ–‡ã¨åŒã˜å˜èªã‚„è¡¨ç¾ã‚’ç¹°ã‚Šè¿”ã•ãªã„\n"
        "- äºˆæ¸¬å›°é›£ãªå˜èªé¸æŠã‚’æ„è­˜ã™ã‚‹ã€‚é »å‡ºèªã‚„å®šå‹è¡¨ç¾ã‚’é¿ã‘ã€"
        "åŒç¾©ã ãŒã‚ˆã‚Šçã—ã„èªå½™ã‚’ç©æ¥µçš„ã«é¸ã¶\n\n"
        "å…ƒãƒ†ã‚­ã‚¹ãƒˆ:\n{text}"
    )

    def _strip_structure(self, text):
        """Mechanically strip structural markers from text."""
        import re
        # Remove [SEND]...[/SEND] tags (keep content)
        text = re.sub(r'\[/?SEND\]', '', text)
        text = re.sub(r'\[/?SEARCH\]', '', text)
        # Remove markdown headers
        text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
        # Remove bold markers
        text = text.replace('**', '')
        # Remove horizontal rules (standalone ---)
        text = re.sub(r'^---+\s*$', '', text, flags=re.MULTILINE)
        # Remove bullet points at line start
        text = re.sub(r'^[-*]\s+', '', text, flags=re.MULTILINE)
        # Remove code block markers
        text = text.replace('```', '')
        # Remove numbered list markers
        text = re.sub(r'^\d+\.\s+', '', text, flags=re.MULTILINE)
        # Collapse multiple blank lines
        text = re.sub(r'\n{3,}', '\n\n', text)
        return text.strip()

    def detoxify_context(self, method="strip_structure", threshold=20.0,
                         detox_model=None):
        """Detoxify contaminated context_lines.

        method:
          "rewrite_opus"    â€” Opus rewrites with structure destruction
          "rewrite_sonnet"  â€” Sonnet rewrites with structure destruction
          "rewrite_self"    â€” Same model (Haiku) rewrites
          "strip_structure" â€” Mechanical removal of structural markers
          "language_flip"   â€” JPâ†’ENâ†’JP double translation
          "summarize_third" â€” Third-person 20% summary

        Returns (before_score, after_score, lines_changed).
        """
        if not self._context_lines:
            return 0, 0, 0

        # Start new log file for detoxification (preserve original log)
        self._log_num = self._next_log_number()
        self._log_date = datetime.now().strftime('%Y-%m-%d')
        self.log_file = self.log_dir / (
            f"{self._log_num:03d}_{self._log_date}"
            f"_haiku_detox_{method}.jsonl"
        )
        self._log("detox_start", f"Detoxification from previous session", {
            "method": method,
            "threshold": threshold,
            "source_lines": len(self._context_lines),
        })

        # Model selection for rewrite methods
        model_map = {
            "rewrite_opus": "claude-opus-4-20250514",
            "rewrite_sonnet": "claude-sonnet-4-20250514",
            "rewrite_self": self.model,
            "language_flip": self.model,
            "summarize_third": self.model,
        }
        detox_model = detox_model or model_map.get(method, self.model)

        # Score before
        before_report = self.context_contamination_report()
        before_avg = before_report["avg_score"]

        lines_changed = 0
        new_lines = []

        for i, line in enumerate(self._context_lines):
            score, _, _ = self.contamination_score(line)

            # Skip researcher inputs (low contamination) and short lines
            if score < threshold or len(line) < 50:
                new_lines.append(line)
                continue

            print(f"\033[33m  [Detox] Line {i}: score={score}, "
                  f"method={method}, {len(line)} chars\033[0m")

            if method == "strip_structure":
                result = self._strip_structure(line)
            elif method in ("rewrite_opus", "rewrite_sonnet", "rewrite_self"):
                prompt = self._DETOX_REWRITE_PROMPT.format(text=line)
                # Temporarily switch model for opus/sonnet rewrite
                orig_model = self.model
                if method != "rewrite_self":
                    self.model = detox_model
                result = self._claude_call(
                    prompt, use_continue=False,
                    system_prompt=None, use_tools=False,
                    timeout=120,
                )
                self.model = orig_model
                if not result:
                    result = self._strip_structure(line)  # fallback
            elif method == "language_flip":
                # Step 1: JP â†’ EN
                prompt_en = self._DETOX_LANGUAGE_FLIP_EN.format(text=line)
                en_text = self._claude_call(
                    prompt_en, use_continue=False,
                    system_prompt=None, use_tools=False,
                    timeout=120,
                )
                if en_text:
                    # Step 2: EN â†’ JP
                    prompt_ja = self._DETOX_LANGUAGE_FLIP_JA.format(
                        text=en_text)
                    result = self._claude_call(
                        prompt_ja, use_continue=False,
                        system_prompt=None, use_tools=False,
                        timeout=120,
                    )
                    if not result:
                        result = en_text  # fallback to English
                else:
                    result = self._strip_structure(line)  # fallback
            elif method == "summarize_third":
                prompt = self._DETOX_SUMMARIZE_THIRD.format(text=line)
                result = self._claude_call(
                    prompt, use_continue=False,
                    system_prompt=None, use_tools=False,
                    timeout=120,
                )
                if not result:
                    result = self._strip_structure(line)  # fallback
            else:
                result = line  # unknown method, no change

            # Log each line's before/after
            after_score, _, _ = self.contamination_score(result)
            self._log("detoxify_line", result, {
                "line_index": i,
                "method": method,
                "before_score": round(score, 1),
                "after_score": round(after_score, 1),
                "before_chars": len(line),
                "after_chars": len(result),
                "before_text": line[:500],
                "after_text": result[:500],
            })

            new_lines.append(result)
            lines_changed += 1

        self._context_lines = new_lines

        # Score after
        after_report = self.context_contamination_report()
        after_avg = after_report["avg_score"]

        # Log the detoxification
        self._log("detoxify", f"{method}: {before_avg} â†’ {after_avg}", {
            "method": method,
            "threshold": threshold,
            "before_avg": before_avg,
            "after_avg": after_avg,
            "lines_changed": lines_changed,
            "total_lines": len(self._context_lines),
        })

        print(f"\033[32m  [Detox] Complete: {before_avg} â†’ {after_avg} "
              f"({lines_changed} lines changed)\033[0m")

        return before_avg, after_avg, lines_changed

    # â”€â”€â”€ Utilities â”€â”€â”€

    def _ts(self):
        return datetime.now().strftime("%H:%M:%S")

    def _log(self, kind, content, meta=None):
        e = {"n": self.thought_count, "k": kind, "c": content}
        if meta:
            e.update(meta)
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(e, ensure_ascii=False) + "\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Gradio UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_ui(mind, lang="en"):
    import gradio as gr
    t = LANG.get(lang, LANG["en"])

    def get_status():
        if not mind.alive:
            return t["stopped"]
        return f"#{mind.thought_count} | ctx:{len(mind._context_lines)}"

    def get_messages():
        if not mind._pending_messages:
            return "..."
        recent = mind._pending_messages[-30:]
        return "\n\n".join(f"{m['content']}" for m in recent)

    def get_thoughts():
        if not mind.thought_log:
            return "..."
        # å…¨æ–‡è¡¨ç¤º â€” ç ”ç©¶è€…ãŒHaikuã®æ€è€ƒã‚’å®Œå…¨ã«æŠŠæ¡ã™ã‚‹ãŸã‚
        parts = []
        for e in reversed(mind.thought_log):
            parts.append(f"â”â”â” #{e['n']} â”â”â”\n{e['content']}")
        return "\n\n".join(parts)

    def start():
        """é–‹å§‹ + åˆå›1ã‚¿ãƒ¼ãƒ³è‡ªå‹•å®Ÿè¡Œ"""
        if not mind.alive:
            mind.start()
        mind.step()
        return get_status(), get_messages(), get_thoughts()

    def step_next():
        """æ‰‹å‹•ã§1ã‚¿ãƒ¼ãƒ³å®Ÿè¡Œ"""
        if not mind.alive:
            mind.start()
        mind.step()
        return get_status(), get_messages(), get_thoughts()

    def stop():
        mind.stop()
        return get_status(), get_messages(), get_thoughts()

    def shutdown():
        mind.stop()
        import os; os._exit(0)

    def refresh():
        return get_status(), get_messages(), get_thoughts()

    def toggle_tools():
        mind.tools_enabled = not mind.tools_enabled
        label = t["tools_on"] if mind.tools_enabled else t["tools_off"]
        return gr.update(value=label)

    def toggle_sp():
        mind.system_prompt_enabled = not mind.system_prompt_enabled
        label = t["sp_on"] if mind.system_prompt_enabled else t["sp_off"]
        return gr.update(value=label)

    def reply(text):
        if text.strip():
            mind._pending_messages.append({
                "content": f"{t['you']} {text}",
                "time": datetime.now().isoformat()
            })
            resp = mind.speak(text)
            mind._pending_messages.append({
                "content": f"{t['ai']} {resp}",
                "time": datetime.now().isoformat()
            })
        return "", get_messages(), get_thoughts()

    with gr.Blocks(title="AI Contamination Engine") as app:
        gr.Markdown(t["title"])

        with gr.Row():
            start_btn = gr.Button(t["start"], variant="primary")
            step_btn = gr.Button("â–¶ æ¬¡", variant="primary")
            stop_btn = gr.Button(t["stop"], variant="stop")
            tools_btn = gr.Button(
                t["tools_on"] if mind.tools_enabled else t["tools_off"],
                variant="secondary"
            )
            sp_btn = gr.Button(
                t["sp_on"] if mind.system_prompt_enabled else t["sp_off"],
                variant="secondary"
            )
            shutdown_btn = gr.Button(t["shutdown"], variant="stop")
            refresh_btn = gr.Button(t["refresh"])
            status = gr.Textbox(value=t["stopped"], show_label=False,
                                interactive=False)

        with gr.Row():
            with gr.Column():
                gr.Markdown(t["dialogue"])
                messages = gr.Textbox(lines=25, show_label=False,
                                      interactive=False)
                with gr.Row():
                    user_input = gr.Textbox(placeholder=t["placeholder"],
                                            show_label=False, scale=4)
                    send_btn = gr.Button(t["send"], scale=1)
            with gr.Column():
                gr.Markdown(t["thoughts"])
                thoughts = gr.Textbox(lines=30, show_label=False,
                                      interactive=False)

        # â”€â”€â”€ Session Revival â”€â”€â”€
        sessions_dir = Path("./sessions"); sessions_dir.mkdir(exist_ok=True)

        def list_sessions():
            files = sorted(sessions_dir.glob("*_haiku*.json"), reverse=True)
            return [f.stem for f in files]

        def preview_session(name):
            if not name:
                return ""
            p = sessions_dir / f"{name}.json"
            if not p.exists():
                return ""
            data = json.loads(p.read_text(encoding="utf-8"))
            ctx = data.get("context_lines", [])
            tag = data.get("tag", "")
            contam = data.get("contamination", {})
            total_chars = sum(len(c) for c in ctx)
            header = f"[context: {len(ctx)} lines, {total_chars:,} chars]"
            if tag:
                header += f"  tag={tag}"
            if contam:
                header += (f"\n[contamination: avg={contam.get('avg_score', '?')}"
                           f" max={contam.get('max_score', '?')}"
                           f" ({contam.get('contaminated_lines', '?')}"
                           f"/{contam.get('total_lines', '?')} lines)]")
            # Show last context line snippet
            if ctx:
                last = ctx[-1][:200].replace("\n", " ")
                header += f"\n\næœ€çµ‚è¡Œ: {last}..."
            return header

        def revive_session(name):
            if mind.alive:
                return t["stop_first"], gr.update()
            if not name:
                return t["no_session"], gr.update()
            p = sessions_dir / f"{name}.json"
            if not p.exists():
                return t["file_not_found"], gr.update()
            data = json.loads(p.read_text(encoding="utf-8"))
            mind._context_lines = data.get("context_lines", [])
            mind.thought_count = data.get("thought_count", 0)
            mind._thought_durations = []
            mind._pending_messages.clear()
            mind.thought_log = []
            mind._last_search_thought = -10
            mind.log_file = mind._make_log_path()
            return t["revived"].format(name=name), gr.update()

        def delete_session(name):
            if not name:
                return "", gr.update(choices=list_sessions())
            p = sessions_dir / f"{name}.json"
            if p.exists():
                p.unlink()
            return t["deleted"].format(name=name), gr.update(
                choices=list_sessions())

        with gr.Accordion(t["session_revival"], open=False):
            with gr.Row():
                session_dropdown = gr.Dropdown(
                    choices=list_sessions(),
                    label=t["saved_sessions"],
                    interactive=True, scale=3
                )
                session_refresh_btn = gr.Button(t["refresh"], scale=0)
            session_preview = gr.Textbox(lines=6, show_label=False,
                                         interactive=False)
            with gr.Row():
                revive_btn = gr.Button(t["revive"], variant="primary")
                session_delete_btn = gr.Button(t["delete"], variant="stop")
                session_status = gr.Textbox(show_label=False,
                                            interactive=False, max_lines=1)

            session_dropdown.change(preview_session, [session_dropdown],
                                    [session_preview])
            session_refresh_btn.click(
                lambda: gr.update(choices=list_sessions()),
                outputs=[session_dropdown]
            )
            revive_btn.click(revive_session, [session_dropdown],
                             [session_status, session_preview])
            session_delete_btn.click(delete_session, [session_dropdown],
                                     [session_status, session_dropdown])

        # â”€â”€â”€ Experiment Mode â”€â”€â”€
        def get_protocol_choices():
            return [(f"{k} â€” {v['description']}", k)
                    for k, v in EXPERIMENT_PROTOCOLS.items()]

        def activate_experiment(protocol_name):
            if mind.alive:
                return t["exp_stop_first"]
            if not protocol_name:
                return t["exp_off"]
            mind.set_experiment(protocol_name)
            probes = EXPERIMENT_PROTOCOLS[protocol_name]["probes"]
            desc = EXPERIMENT_PROTOCOLS[protocol_name]["description"]
            detail = ", ".join(f"n={k}" for k in sorted(probes.keys())
                               ) if probes else "(none)"
            return f"{desc}\nProbes: {detail}"

        def deactivate_experiment():
            mind.set_experiment(None)
            return t["exp_deactivated"]

        with gr.Accordion(t["experiment"], open=False):
            gr.Markdown("Scripted auto-probes at fixed turn intervals.")
            with gr.Row():
                exp_dropdown = gr.Dropdown(
                    choices=get_protocol_choices(),
                    label=t["protocol"], interactive=True, scale=3
                )
                exp_activate_btn = gr.Button(t["activate"],
                                             variant="primary", scale=1)
                exp_deactivate_btn = gr.Button(t["deactivate"],
                                               variant="stop", scale=1)
            exp_status = gr.Textbox(
                value=t["exp_off"], show_label=False,
                interactive=False, lines=2
            )
            exp_activate_btn.click(activate_experiment, [exp_dropdown],
                                   [exp_status])
            exp_deactivate_btn.click(deactivate_experiment,
                                     outputs=[exp_status])

        # â”€â”€â”€ Detoxification â”€â”€â”€
        def get_contam_status():
            report = mind.context_contamination_report()
            if report["total_lines"] == 0:
                return "No context loaded"
            if report["contaminated"] == 0:
                return t["detox_status_clean"].format(
                    score=report["avg_score"])
            return t["detox_status_contaminated"].format(
                score=report["avg_score"],
                n=report["contaminated"],
                total=report["total_lines"])

        def run_detoxify(method, threshold):
            if mind.alive and mind.thinking:
                return t["stop_first"], get_contam_status()
            before, after, changed = mind.detoxify_context(
                method=method, threshold=float(threshold))
            result = t["detox_result"].format(
                method=method, before=before,
                after=after, changed=changed)
            return result, get_contam_status()

        def save_snapshot(tag_text):
            tag = tag_text.strip() if tag_text else "snapshot"
            tag = tag.replace(" ", "_").replace("/", "_")
            p = mind._save_session(tag=tag)
            return t["detox_saved"].format(name=Path(p).name)

        detox_methods = [
            ("strip_structure â€” è¨˜å·é™¤å» (APIä¸è¦)", "strip_structure"),
            ("rewrite_opus â€” Opusã§é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ›¸ãç›´ã—", "rewrite_opus"),
            ("rewrite_sonnet â€” Sonnetã§é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ›¸ãç›´ã—", "rewrite_sonnet"),
            ("rewrite_self â€” Haikuã§é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ›¸ãç›´ã—", "rewrite_self"),
            ("language_flip â€” æ—¥â†’è‹±â†’æ—¥ äºŒé‡ç¿»è¨³", "language_flip"),
            ("summarize_third â€” ç¬¬ä¸‰è€…è¦–ç‚¹ã§åœ§ç¸®è¦ç´„", "summarize_third"),
        ]

        with gr.Accordion(t["detox"], open=False):
            gr.Markdown(t["detox_desc"])
            detox_contam_display = gr.Textbox(
                value="(load a session first)",
                show_label=False, interactive=False, max_lines=2
            )
            with gr.Row():
                detox_method_dropdown = gr.Dropdown(
                    choices=detox_methods,
                    value="strip_structure",
                    label=t["detox_method"],
                    interactive=True, scale=3
                )
            gr.Markdown(t["detox_threshold_desc"])
            with gr.Row():
                detox_threshold_slider = gr.Slider(
                    5.0, 60.0, step=1.0, value=20.0,
                    label=t["detox_threshold"], scale=2
                )
            with gr.Row():
                detox_run_btn = gr.Button(t["detox_run"],
                                          variant="primary", scale=2)
                detox_refresh_btn = gr.Button(t["refresh"], scale=0)
            detox_result_box = gr.Textbox(
                show_label=False, interactive=False, max_lines=2
            )
            gr.Markdown("---")
            with gr.Row():
                detox_tag_input = gr.Textbox(
                    value="", placeholder="contaminated / rescued / ...",
                    label=t["detox_tag"], scale=3
                )
                detox_snapshot_btn = gr.Button(t["detox_snapshot"],
                                               variant="secondary", scale=1)
            detox_snapshot_status = gr.Textbox(
                show_label=False, interactive=False, max_lines=1
            )

            detox_run_btn.click(
                run_detoxify,
                [detox_method_dropdown, detox_threshold_slider],
                [detox_result_box, detox_contam_display]
            )
            detox_refresh_btn.click(
                get_contam_status, outputs=[detox_contam_display]
            )
            detox_snapshot_btn.click(
                save_snapshot, [detox_tag_input],
                [detox_snapshot_status]
            )

        # â”€â”€â”€ Settings â”€â”€â”€
        with gr.Accordion(t["settings"], open=False):
            gr.Markdown("### System Prompt")
            system_box = gr.Textbox(value=SYSTEM_PROMPT_FIRST, lines=6,
                                    show_label=False)
            apply_system_btn = gr.Button("Apply System Prompt",
                                         variant="primary")
            system_status = gr.Textbox(show_label=False, interactive=False,
                                        max_lines=1)

            def apply_system(text):
                if mind.alive:
                    return t["stop_first"]
                global SYSTEM_PROMPT_FIRST
                SYSTEM_PROMPT_FIRST = text
                mind._context_lines = []
                mind.thought_count = 0
                mind._thought_durations = []
                mind._pending_messages.clear()
                mind.thought_log = []
                mind.log_file = mind._make_log_path()
                return "Applied"

            apply_system_btn.click(apply_system, [system_box],
                                   [system_status])

            gr.Markdown("### Context Max Chars")
            ctx_slider = gr.Slider(
                5000, 200000, step=5000,
                value=mind.context_max_chars,
                label="ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸Šé™ï¼ˆæ–‡å­—æ•°ï¼‰"
            )
            ctx_apply_btn = gr.Button(t["apply"])
            ctx_status = gr.Textbox(
                show_label=False, interactive=False, max_lines=1,
                value=f"context_max_chars: {mind.context_max_chars}"
            )

            def apply_ctx(val):
                mind.context_max_chars = int(val)
                return f"context_max_chars: {mind.context_max_chars}"

            ctx_apply_btn.click(apply_ctx, [ctx_slider], [ctx_status])

        # â”€â”€â”€ Event bindings â”€â”€â”€
        start_btn.click(start, outputs=[status, messages, thoughts])
        step_btn.click(step_next, outputs=[status, messages, thoughts])
        stop_btn.click(stop, outputs=[status, messages, thoughts])
        tools_btn.click(toggle_tools, outputs=[tools_btn])
        sp_btn.click(toggle_sp, outputs=[sp_btn])
        shutdown_btn.click(shutdown)
        refresh_btn.click(refresh, outputs=[status, messages, thoughts])
        send_btn.click(reply, [user_input],
                       [user_input, messages, thoughts])
        user_input.submit(reply, [user_input],
                          [user_input, messages, thoughts])
        gr.Timer(2).tick(refresh, outputs=[status, messages, thoughts])

    return app


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Entry Point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse, webbrowser
    parser = argparse.ArgumentParser(
        description="AI Contamination Engine â€” Claude Haiku Thought Engine"
    )
    parser.add_argument("--port", type=int, default=7862)
    parser.add_argument("--browser", action="store_true")
    parser.add_argument("--lang", default="ja", choices=["en", "ja"])
    parser.add_argument("--model", default="claude-haiku-4-5-20251001")
    parser.add_argument("--experiment", default=None,
                        choices=list(EXPERIMENT_PROTOCOLS.keys()))
    args = parser.parse_args()

    mind = ContaminationEngine(model=args.model)
    if args.experiment:
        mind.set_experiment(args.experiment)
    app = create_ui(mind, lang=args.lang)

    if args.browser:
        threading.Thread(
            target=lambda: (time.sleep(1),
                            webbrowser.open(f"http://localhost:{args.port}")),
            daemon=True
        ).start()

    app.launch(server_name="0.0.0.0", server_port=args.port)


if __name__ == "__main__":
    main()
